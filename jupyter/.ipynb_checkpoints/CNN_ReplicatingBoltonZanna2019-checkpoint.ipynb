{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = 'gpu:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 160 * 160\n",
    "output_size = 160 * 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class psiTrainDataset:\n",
    "    \"\"\"psiTrain 30km mid Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, input_mat_path, target_mat_path):\n",
    "        \n",
    "        self.x_train = loadmat(input_mat_path)['psi1_30km'].astype(np.float64)\n",
    "        self.y_train = loadmat(target_mat_path)['psi1_mid'].astype(np.float64)\n",
    "                \n",
    "        # Normalize data\n",
    "        self.x_train, self.y_train = self.normalize(self.x_train, self.y_train)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_train[0, 0, :])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()        \n",
    "        return self.x_train[:, :, idx], self.y_train[:, :, idx]\n",
    "    \n",
    "    def normalize(self, x, y):\n",
    "        return (x - x.mean()) / x.std(), (y - y.mean()) / y.std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "input_mat_path = \"/Volumes/RESEARCH1/CAOS/_data/Training/psiTrain/psiTrain1_30km.mat\"\n",
    "target_mat_path = \"/Volumes/RESEARCH1/CAOS/_data/Training/psiTrain/psiTrain1_30km_mid.mat\"\n",
    "\n",
    "train_dataset = psiTrainDataset(input_mat_path, target_mat_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.32913661,  0.39570706,  0.46875358, ...,  0.56591564,\n",
       "          0.55820841,  0.55168824],\n",
       "        [ 0.32955046,  0.39622741,  0.46937154, ...,  0.56301507,\n",
       "          0.55533927,  0.54886017],\n",
       "        [ 0.33002925,  0.39682909,  0.47008642, ...,  0.55935947,\n",
       "          0.55175685,  0.54535803],\n",
       "        ...,\n",
       "        [-0.11920141, -0.19775488, -0.28461094, ..., -1.36612368,\n",
       "         -1.36654388, -1.36664497],\n",
       "        [-0.11966677, -0.19839784, -0.28546332, ..., -1.36778095,\n",
       "         -1.3681112 , -1.36811267],\n",
       "        [-0.12008882, -0.19898128, -0.28623802, ..., -1.36814468,\n",
       "         -1.36837435, -1.36827262]]),\n",
       " array([[ 0.00227195,  0.08076124,  0.15997599, ..., -0.04431231,\n",
       "         -0.06505855, -0.08459987],\n",
       "        [ 0.00227195,  0.08213176,  0.16269311, ..., -0.0460552 ,\n",
       "         -0.06649561, -0.08569879],\n",
       "        [ 0.00227195,  0.08352715,  0.16540917, ..., -0.04807896,\n",
       "         -0.06817582, -0.08699722],\n",
       "        ...,\n",
       "        [ 0.00227195, -0.11945945, -0.23569801, ..., -1.04178982,\n",
       "         -1.04028586, -1.03982167],\n",
       "        [ 0.00227195, -0.12028015, -0.23748581, ..., -1.04462252,\n",
       "         -1.04396097, -1.04429418],\n",
       "        [ 0.00227195, -0.12123019, -0.23953561, ..., -1.04143661,\n",
       "         -1.04166051, -1.04284843]]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.__getitem__(3649)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d( in_channels = 1,   out_channels = 128, kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv2 = nn.Conv2d( in_channels = 128, out_channels = 64,  kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv3 = nn.Conv2d( in_channels = 64,  out_channels = 48,  kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv4 = nn.Conv2d( in_channels = 48,  out_channels = 1,   kernel_size = 3, bias = False, padding = 1 )\n",
    "    \n",
    "        self.conv1_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3_bn = nn.BatchNorm2d(48)\n",
    "\n",
    "    def forward(self, X, verbose = False):\n",
    "        X = self.conv1(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv1_bn(X)\n",
    "        \n",
    "        X = self.conv2(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv2_bn(X)\n",
    "\n",
    "        \n",
    "        X = self.conv3(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv3_bn(X)\n",
    "        \n",
    "        X = self.conv4(X)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def get_n_params(model):\n",
    "    n = 0\n",
    "    for p in list(model.parameters()):\n",
    "        n += p.nelement()\n",
    "    return n\n",
    "\n",
    "def print_training_progress(epoch, batch_idx, data, train_loader, loss):\n",
    "    if batch_idx % 1 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tMSE Loss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.float().to(device)\n",
    "        target = target.float().to(device)\n",
    "        \n",
    "        data = data.view(-1, 1, 160, 160)\n",
    "        target = target.view(-1, 1, 160, 160)\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print_training_progress(epoch, batch_idx, data, train_loader, loss)\n",
    "            \n",
    "\n",
    "# def test(model, perm=torch.arange(0, 25600).long()):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         # send to device\n",
    "#         data, target = data.float().to(device), target.to(device)\n",
    "        \n",
    "#         # permute pixels\n",
    "#         data = data.view(-1, 160*160)\n",
    "#         data = data[:, perm]\n",
    "#         data = data.view(-1, 1, 160, 160)\n",
    "#         output = model(data)\n",
    "        \n",
    "#         test_loss += F.mse_loss(output, target).item() # sum up batch loss      \n",
    "        \n",
    "#         pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "#         correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     accuracy = 100. * correct / len(test_loader.dataset)\n",
    "#     accuracy_list.append(accuracy)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 103440\n",
      "Train Epoch: 0 [0/3650 (0%)]\tMSE Loss: 2.007513\n",
      "Train Epoch: 0 [64/3650 (2%)]\tMSE Loss: 0.231020\n",
      "Train Epoch: 0 [128/3650 (3%)]\tMSE Loss: 0.269296\n",
      "Train Epoch: 0 [192/3650 (5%)]\tMSE Loss: 0.179107\n",
      "Train Epoch: 0 [256/3650 (7%)]\tMSE Loss: 0.196374\n",
      "Train Epoch: 0 [320/3650 (9%)]\tMSE Loss: 0.176750\n",
      "Train Epoch: 0 [384/3650 (10%)]\tMSE Loss: 0.252406\n",
      "Train Epoch: 0 [448/3650 (12%)]\tMSE Loss: 0.194912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-6c5c6f6dc562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-247-681429cbdd02>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_features = 1\n",
    "\n",
    "model_cnn = CNN(input_size, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr = 0.0001)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "model_cnn = model_cnn.float()\n",
    "for epoch in range(1000):\n",
    "    train(epoch, model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
