{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "cuda = 'gpu:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT Data Files\n",
    "\n",
    "matpath_upper = \"/Volumes/RESEARCH1/CAOS/_data/Training/psiTrain/psiTrain1_30km.mat\"\n",
    "matpath_mid = \"/Volumes/RESEARCH1/CAOS/_data/Training/psiTrain/psiTrain1_30km_mid.mat\"\n",
    "\n",
    "psi1_upper = loadmat(matpath_upper)\n",
    "psi1_mid = loadmat(matpath_mid)\n",
    "\n",
    "psi1_upper_30km_filter = psi1_upper['psi1_30km'].astype(np.float64)\n",
    "psi1_upper_anomaly = psi1_upper['psi1Anom'].astype(np.float64)\n",
    "psi1_upper_unfiltered = psi1_upper_30km_filter + psi1_upper_anomaly\n",
    "\n",
    "psi1_mid_unfiltered = psi1_mid['psi1_mid'].astype(np.float64)\n",
    "psi1_top_30km = psi1_mid['psi1_top_30km'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class psi1_Dataset:\n",
    "    \"\"\"psiTrain 30km mid Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, is_train, train_split):\n",
    "        n_total_samples = len(X[0, 0, :])\n",
    "        split_idx = int(np.floor(train_split * n_total_samples))\n",
    "\n",
    "        x_train = X[:, :, :split_idx]\n",
    "        y_train = Y[:, :, :split_idx]\n",
    "\n",
    "        x_test = X[:, :, split_idx:]\n",
    "        y_test = Y[:, :, split_idx:]\n",
    "\n",
    "        # Differentiate Train v. Test & Normalize\n",
    "        \n",
    "        x_mean, x_std = x_train.mean(), x_train.std()\n",
    "        y_mean, y_std = y_train.mean(), y_train.std()\n",
    "        \n",
    "        if is_train:\n",
    "            self.x = (x_train - x_mean) / x_std\n",
    "            self.y = (y_train - y_mean) / y_std\n",
    "        else:\n",
    "            self.x = (x_test - x_mean) / x_std\n",
    "            self.y = (y_test - y_mean) / y_std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x[0, 0, :])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()        \n",
    "        return self.x[:, :, idx], self.y[:, :, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_split = 0.888888\n",
    "\n",
    "# Create Train/Test datasets\n",
    "train_dataset = psi1_Dataset(X = psi1_upper_30km_filter,\n",
    "                             Y = psi1_upper_anomaly,\n",
    "                             is_train = True,\n",
    "                             train_split = train_split)\n",
    "\n",
    "test_dataset = psi1_Dataset(X = psi1_upper_30km_filter,\n",
    "                            Y = psi1_upper_anomaly,\n",
    "                            is_train = False,\n",
    "                            train_split = train_split)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d( in_channels = 1,   out_channels = 128, kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv2 = nn.Conv2d( in_channels = 128, out_channels = 64,  kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv3 = nn.Conv2d( in_channels = 64,  out_channels = 48,  kernel_size = 3, bias = False, padding = 1 )\n",
    "        self.conv4 = nn.Conv2d( in_channels = 48,  out_channels = 1,   kernel_size = 3, bias = False, padding = 1 )\n",
    "        \n",
    "#         f = np.random.rand(5, 5).astype(np.float32)\n",
    "#         f = f.reshape(1, 1, f.shape[0], f.shape[1])\n",
    "#         f = np.repeat(f, 100, axis=1)\n",
    "#         f = np.repeat(f, 100, axis=0)\n",
    "#         self.f = nn.Parameter(data=torch.FloatTensor(f), requires_grad=False)\n",
    "#         self.conv4 = nn.conv2d(x, self.f)\n",
    "    \n",
    "        self.conv1_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3_bn = nn.BatchNorm2d(48)\n",
    "\n",
    "    def forward(self, X, verbose = False):\n",
    "        X = self.conv1(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv1_bn(X)\n",
    "        \n",
    "        X = self.conv2(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv2_bn(X)\n",
    "\n",
    "        \n",
    "        X = self.conv3(X)\n",
    "        X = F.selu(X)\n",
    "        X = self.conv3_bn(X)\n",
    "        \n",
    "        X = self.conv4(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_list = []\n",
    "\n",
    "def get_n_params(model):\n",
    "    n = 0\n",
    "    for p in list(model.parameters()):\n",
    "        n += p.nelement()\n",
    "    return n\n",
    "\n",
    "def print_training_progress(epoch, batch_idx, data, train_loader, loss):\n",
    "    training_loss_list.append(loss.item())\n",
    "    if batch_idx % 1 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tMSE Loss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "        \n",
    "        data = data.view(-1, 1, 160, 160)\n",
    "        target = target.view(-1, 1, 160, 160)\n",
    "        \n",
    "        #BACKPROP\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print_training_progress(epoch, batch_idx, data, train_loader, loss)\n",
    "            \n",
    "            \n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "        test_loss += F.mse_loss(output, target).item() # sum up batch loss      \n",
    "\n",
    "    test_loss /= n_samples\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples:  3244\n",
      "Test Samples:  406 \n",
      "\n",
      "Number of parameters: 103440\n",
      "Train Epoch: 0 [0/3244 (0%)]\tMSE Loss: 1.182438\n",
      "Train Epoch: 0 [64/3244 (2%)]\tMSE Loss: 0.964907\n",
      "Train Epoch: 0 [128/3244 (4%)]\tMSE Loss: 0.725993\n",
      "Train Epoch: 0 [192/3244 (6%)]\tMSE Loss: 0.711924\n",
      "Train Epoch: 0 [256/3244 (8%)]\tMSE Loss: 0.665670\n",
      "Train Epoch: 0 [320/3244 (10%)]\tMSE Loss: 0.723600\n",
      "Train Epoch: 0 [384/3244 (12%)]\tMSE Loss: 0.640117\n",
      "Train Epoch: 0 [448/3244 (14%)]\tMSE Loss: 0.576984\n",
      "Train Epoch: 0 [512/3244 (16%)]\tMSE Loss: 0.599961\n",
      "Train Epoch: 0 [576/3244 (18%)]\tMSE Loss: 0.574386\n",
      "Train Epoch: 0 [640/3244 (20%)]\tMSE Loss: 0.603774\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-b1f7d54ad9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-56854889e178>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#BACKPROP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-39cc6437ea0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "input_size = 160 * 160\n",
    "output_size = 160 * 160\n",
    "\n",
    "print(\"Train Samples: \", len(train_loader.dataset))\n",
    "print(\"Test Samples: \", len(test_loader.dataset), '\\n')\n",
    "\n",
    "model_cnn = CNN(input_size, output_size)\n",
    "model_cnn.float().to(device)\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr = 0.0001)\n",
    "\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch, model_cnn)\n",
    "\n",
    "test(model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
